"""
Test script for new PP-OCRv5 Det and Rec ONNX models
"""

import cv2
import numpy as np
from pathlib import Path

# Import the new classes
from app.core.pp_onnx.pp_ocrv5det_onnx_new import PPOCRv5DetONNX
from app.core.pp_onnx.pp_ocrv5rec_onnx_new import PPOCRv5RecONNX


def main():
    # Path to test image
    test_image_path = Path(__file__).parent / 'test_2026.png'

    if not test_image_path.exists():
        print(f"Test image not found at {test_image_path}")
        return

    # Load image
    image = cv2.imread(str(test_image_path))
    if image is None:
        print(f"Could not load image: {test_image_path}")
        return

    print("Loaded test image")

    # Initialize detectors
    try:
        det_model = PPOCRv5DetONNX()
        rec_model = PPOCRv5RecONNX()
        print("Models initialized successfully")
        print(f"Rec model label_list length: {len(rec_model.label_list)}")
        print(f"Rec model label_list[:10]: {rec_model.label_list[:10]}")
    except Exception as e:
        print(f"Error initializing models: {e}")
        return

    # Run detection
    try:
        detections = det_model.detect(image, conf_threshold=0.3, use_close=True)
        print(f"Detected {len(detections)} text regions")
        for i, det in enumerate(detections):
            print(f"  Region {i}: {det}")
    except Exception as e:
        print(f"Error in detection: {e}")
        return

    # Create test_det directory
    test_det_dir = Path(__file__).parent / 'test_det'
    test_det_dir.mkdir(exist_ok=True)

    # Save cropped detection regions
    for i, det in enumerate(detections):
        bbox = det['bbox']
        x1, y1, x2, y2 = bbox

        # Crop the text region
        cropped = image[y1:y2, x1:x2]
        if cropped.size == 0:
            continue

        # Save cropped image
        crop_path = test_det_dir / f'region_{i:02d}.png'
        cv2.imwrite(str(crop_path), cropped)
        print(f"Saved cropped region {i} to {crop_path}")

    # For each detection, crop and recognize
    results = []
    for i, det in enumerate(detections):
        bbox = det['bbox']
        x1, y1, x2, y2 = bbox

        # Crop the text region
        cropped = image[y1:y2, x1:x2]
        if cropped.size == 0:
            continue

        # Run recognition
        try:
            rec_result = rec_model.recognize(cropped, conf_threshold=0.5)
            print(f"  Region {i} text: '{rec_result['text']}' (conf: {rec_result['confidence']:.2f})")
            results.append({
                'bbox': bbox,
                'text': rec_result['text'],
                'confidence': rec_result['confidence']
            })
        except Exception as e:
            print(f"Error in recognition for region {i}: {e}")

    # Visualize results
    vis_image = image.copy()
    for result in results:
        bbox = result['bbox']
        text = result['text']
        conf = result['confidence']

        # Draw bbox
        cv2.rectangle(vis_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)

        # Draw text
        label = f"{text} ({conf:.2f})"
        cv2.putText(vis_image, label, (bbox[0], bbox[1] - 5),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

    # Save visualization
    output_path = Path(__file__).parent / 'test_output.png'
    cv2.imwrite(str(output_path), vis_image)
    print(f"Visualization saved to {output_path}")

    # Show image (if running interactively)
    cv2.imshow("OCR Results", vis_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()